# Evaluating TREs against the SATRE specification

**When?**
17th August 2023, 15:00 - 16:00 Europe/London ([see in your time zone](https://arewemeetingyet.com/London/2023-08-17/15:00))

**What?**
_[SATRE (Standardised Architecture for Trusted Research Environments)](https://medium.com/satre) is a DARE UK Driver Project working to standardise access to secure data in trusted research environments. It includes University of Dundee, Alan Turing Institute, UCL, Ulster University, Research Data Scotland._.
[Collaboration Cafes](https://the-turing-way.netlify.app/community-handbook/coworking/coworking-collabcafe.html) are **online collaboration and coworking calls** for anyone interested in learning about, discussing and contributing to the project.

**Who?**
_Anyone_ interested in our project & the TRE space is welcome to join this call. No prior sign-ups needed!

**_All questions, comments, and recommendations are welcome!_**

## Check-in and icebreaker

11 attendees added their names

## How to contribute to the project

Please read a [walkthrough of the project and how to contribute](https://satre-specification.readthedocs.io/en/latest/contributing/walkthrough.html)

## Today's theme: evaluating TREs against the SATRE specification

As well as building out content, the team have been creating a system of evaluation for TREs to determine how they perform against the specification. You can see our current progress here: https://satre-specification.readthedocs.io/en/latest/evaluation.html

You can see what that may look like in our current examples:

- Evaluation of [The Alan Turing Institute Data Safe Haven](https://satre-specification.readthedocs.io/en/latest/evaluations/alan_turing_institute.html#evaluation-alan-turing-institute).
- Evaluation of [Dundee/HIC TREEHOOSE](https://satre-specification.readthedocs.io/en/latest/evaluations/dundee_hic.html#evaluation-dundee-hic).

In this Collaboration Café we want to explore this system with you, including discussing:

- Does this method of evaluation make sense? Is it useful?
- Is it helpful to have reference evaluations from Turing and Dundee/HIC?
- What would make you carry out an evaluation yourself on your own organisation’s TRE? What would prevent you?
- What materials or resources should we put in place to help you carry it out?

## Breakout rooms: Topic proposals and notes

_While no sign-ups are required to attend Collaboration Cafe, if you have an idea for a topic you'd like to discuss in a breakout room, please add it below and put your name next to it. A good place to start to find discussion topics are on the [SATRE Specification GitHub Repository Issue Board](https://github.com/sa-tre/satre-specification/issues)._

All breakout rooms will discuss all questions (and anything you want to) rather than each focus on a specific one.

### Room 1

#### Present

6 attendees

#### Notes

- Does this method of evaluation make sense? Is it useful?
  - Need a defined set of tiers to define a TRE
- Is it helpful to have reference evaluations from Turing and Dundee/HIC?
  - Might be more useful to have an evaluation of things that a tier 0/1/2/3/4 TRE would do
- What would make you carry out an evaluation yourself on your own organisation’s TRE? What would prevent you?
- What materials or resources should we put in place to help you carry it out?
  - Matrix of requirements vs. tier cf. https://arxiv.org/pdf/1908.08737.pdf

#### Summary

- Suggest a matrix like a risk register, by TRE tier and what you do at that specific tier. Show a funder: "We are at SATRE tier 3"
  - What there is now in the spec mixed with the original paper (which paper?)

### Room 2

- Does this method of evaluation make sense? Is it useful?
  - Is 3 categories enough? Do we need a N/A category?
    - E.g. CMMI is normally 5 levels, is 3 sufficient
    - Could we have a 5 way score for higher level capabilities and just 3 for individual components, for the sake of prioritisation
  - Seeing this as a guidance over a formal accreditation, an advantage of a higher number of levels may make it easier to prioritise
  - In consulting, scoring against a framework is a very standard practice.
    - Can do things like create slider diagrams to see the gaps
  - Also not necessary to get the top level in every category
  - Previous customers haven't been interested in being perfect in everything, it's more about figuring out what we should be prioritising
- Is it helpful to have reference evaluations from Turing and Dundee/HIC?
- What would make you carry out an evaluation yourself on your own organisation’s TRE? What would prevent you?
  - If there is some form of accreditation, that will help
  - Self-scoring can help get an internal view of how things are, then have to go through some form of external accreditation to get credibility from third parties
    - This is more like _"if you follow the spec you'll realise what you need to get accreditation"_ rather than be an accreditation itself
    - If this is the case then the accrediting bodies need to be aligned with this SATRE approach
    - If this is a TRE accreditation, which part does it apply to?
      - Just the technical side, governance, data warehouse, what if it's behind an NHS firewall
  - If you're an established TRE, what's the point of measuring yourself against this standard
    - Benefit is less for well-established TREs. No pre-existing TRE should be 'failing' this
  - Would there be a possibility of future funding for TREs to improve? Running a TRE is expensive and if you're already satisfying the accreditation needs you need to satisfy
  - Scoring a TRE against a certain criteria could be a public accessibly way to evaluate TREs
  - Just because you've built a TRE, doesn't mean you're done. It would be good to e.g. health check your TRE once a year.
    - NHS really likes BRAG rating, could see them fitting this into a system like that.
    - Would it get to the point where you, as a TRE, would need to publish your self-assessment against the criteria, and maybe have to do it once a year
- What materials or resources should we put in place to help you carry it out?
  - Simple way might be a spreadsheet with dropdowns, and criteria for responding to those scoring levels
- Do we need a weighting for importance of statements

#### Summary

- Mature TREs will have many processes and even accreditations in place, who is this spec for? for continuous improvement of those or for new TREs
- Scoring mechanism: useful for summary statistics and where the gaps are
- Weight scores by requirement?

### Wrap up

- Content focused or theme focused collaboration cafes?
  - Content would benefit from a broader review
- Co-working day to evaluate yourselves against the specification?
  - At some point we have to test this against existing things, so we kind of need to do this
  - Would it lead to people debating controls
    - Probably, but in a good way

## Agenda

| Time    | Activity                                    |
| ------- | ------------------------------------------- |
| 10 mins | Introductions and breakout room suggestions |
| 20 mins | (1st breakout session)                      |
| 5 mins  | (☕️ Break)                                  |
| 20 mins | (2nd breakout session)                      |
| 5 mins  | :wave: Reflections and close                |
